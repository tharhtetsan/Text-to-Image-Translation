{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image  \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://huggingface.co/api/models/CompVis/stable-diffusion-v1-4/revision/fp16 (Request ID: 8UsdDGT6pHi1eG6uVVTwX)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\gans\\git_upload\\keywords_to_img_research\\test_no.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#If you are running this code locally, you need to either do a 'huggingface-cli login` or paste your User Access Token from here https://huggingface.co/settings/tokens into the use_auth_token field below. \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(model_id, use_auth_token\u001b[39m=\u001b[39;49mtoken, revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfp16\u001b[39;49m\u001b[39m\"\u001b[39;49m, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\pipeline_utils.py:288\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m# 1. Download the checkpoints and configs\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m# use snapshot download here to get it working from from_pretrained\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[1;32m--> 288\u001b[0m     cached_folder \u001b[39m=\u001b[39m snapshot_download(\n\u001b[0;32m    289\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    290\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    291\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    292\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    293\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    294\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    295\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     cached_folder \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\_snapshot_download.py:182\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, repo_type, cache_dir, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, allow_regex, ignore_regex)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39m# if we have internet connection we retrieve the correct folder name from the huggingface api\u001b[39;00m\n\u001b[0;32m    181\u001b[0m _api \u001b[39m=\u001b[39m HfApi()\n\u001b[1;32m--> 182\u001b[0m repo_info \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39;49mrepo_info(\n\u001b[0;32m    183\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id, repo_type\u001b[39m=\u001b[39;49mrepo_type, revision\u001b[39m=\u001b[39;49mrevision, token\u001b[39m=\u001b[39;49mtoken\n\u001b[0;32m    184\u001b[0m )\n\u001b[0;32m    185\u001b[0m filtered_repo_files \u001b[39m=\u001b[39m _filter_repo_files(\n\u001b[0;32m    186\u001b[0m     repo_files\u001b[39m=\u001b[39m[f\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m repo_info\u001b[39m.\u001b[39msiblings],\n\u001b[0;32m    187\u001b[0m     allow_regex\u001b[39m=\u001b[39mallow_regex,\n\u001b[0;32m    188\u001b[0m     ignore_regex\u001b[39m=\u001b[39mignore_regex,\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    190\u001b[0m commit_hash \u001b[39m=\u001b[39m repo_info\u001b[39m.\u001b[39msha\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\hf_api.py:1289\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[1;34m(self, repo_id, revision, repo_type, token, timeout)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[39mGet the info object for a given repo of a given type.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[39m</Tip>\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m repo_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m repo_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_info(\n\u001b[0;32m   1290\u001b[0m         repo_id, revision\u001b[39m=\u001b[39;49mrevision, token\u001b[39m=\u001b[39;49mtoken, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m   1291\u001b[0m     )\n\u001b[0;32m   1292\u001b[0m \u001b[39melif\u001b[39;00m repo_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_info(\n\u001b[0;32m   1294\u001b[0m         repo_id, revision\u001b[39m=\u001b[39mrevision, token\u001b[39m=\u001b[39mtoken, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[0;32m   1295\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\hf_api.py:1136\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, token, timeout, securityStatus)\u001b[0m\n\u001b[0;32m   1132\u001b[0m status_query_param \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msecurityStatus\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m} \u001b[39mif\u001b[39;00m securityStatus \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1134\u001b[0m     path, headers\u001b[39m=\u001b[39mheaders, timeout\u001b[39m=\u001b[39mtimeout, params\u001b[39m=\u001b[39mstatus_query_param\n\u001b[0;32m   1135\u001b[0m )\n\u001b[1;32m-> 1136\u001b[0m _raise_for_status(r)\n\u001b[0;32m   1137\u001b[0m d \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[0;32m   1138\u001b[0m \u001b[39mreturn\u001b[39;00m ModelInfo(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39md)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:84\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m request\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m     77\u001b[0m     \u001b[39m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[0;32m     79\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m401 Client Error: Repository Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mrequest\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m. If the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m repo is private, make sure you are authenticated. (Request ID:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mrequest_id\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m _raise_with_request_id(request)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:95\u001b[0m, in \u001b[0;36m_raise_with_request_id\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m request_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(e\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m     93\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (Request ID: \u001b[39m\u001b[39m{\u001b[39;00mrequest_id\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,) \u001b[39m+\u001b[39m e\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:]\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:90\u001b[0m, in \u001b[0;36m_raise_with_request_id\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m     88\u001b[0m request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Request-Id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     request\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m request_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(e\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/CompVis/stable-diffusion-v1-4/revision/fp16 (Request ID: 8UsdDGT6pHi1eG6uVVTwX)"
     ]
    }
   ],
   "source": [
    "#If you are running this code locally, you need to either do a 'huggingface-cli login` or paste your User Access Token from here https://huggingface.co/settings/tokens into the use_auth_token field below. \n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=token, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rinnakk/japanese-stable-diffusion\n",
      "  Cloning https://github.com/rinnakk/japanese-stable-diffusion to c:\\users\\tharh\\appdata\\local\\temp\\pip-req-build-galsb3pt\n",
      "  Resolved https://github.com/rinnakk/japanese-stable-diffusion to commit 51b91954ffd397f95f2348308a7377c422b43064\n",
      "Collecting diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to c:\\users\\tharh\\appdata\\local\\temp\\pip-install-fx3qosx2\\diffusers_f75f5e710bde4b6487bfe7b1e6095203\n",
      "  Resolved https://github.com/huggingface/diffusers to commit 7c4b38baca6f8c3bbd24c8b458dcd2b507efa129\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: scipy in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from japanese-stable-diffusion==0.1.0) (1.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from japanese-stable-diffusion==0.1.0) (0.1.96)\n",
      "Collecting invisible-watermark\n",
      "  Downloading invisible_watermark-0.1.5-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: transformers in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from japanese-stable-diffusion==0.1.0) (4.22.0.dev0)\n",
      "Requirement already satisfied: gradio in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from japanese-stable-diffusion==0.1.0) (3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (1.23.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (4.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (3.7.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (9.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (0.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (2022.7.25)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (3.0.9)\n",
      "Requirement already satisfied: fastapi in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.82.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.0.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (3.5.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.18.3)\n",
      "Requirement already satisfied: orjson in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (3.7.7)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.12.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.25.1)\n",
      "Requirement already satisfied: paramiko in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (2.11.0)\n",
      "Requirement already satisfied: analytics-python in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (2022.8.2)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (3.15.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (1.9.2)\n",
      "Requirement already satisfied: websockets in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (10.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (1.4.3)\n",
      "Requirement already satisfied: Jinja2 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from gradio->japanese-stable-diffusion==0.1.0) (0.23.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from aiohttp->gradio->japanese-stable-diffusion==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->gradio->japanese-stable-diffusion==0.1.0) (3.3)\n",
      "Requirement already satisfied: backoff==1.10.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from analytics-python->gradio->japanese-stable-diffusion==0.1.0) (1.10.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from analytics-python->gradio->japanese-stable-diffusion==0.1.0) (1.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from analytics-python->gradio->japanese-stable-diffusion==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from analytics-python->gradio->japanese-stable-diffusion==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from requests->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from requests->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (2022.6.15)\n",
      "Requirement already satisfied: starlette==0.19.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from fastapi->gradio->japanese-stable-diffusion==0.1.0) (0.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from starlette==0.19.1->fastapi->gradio->japanese-stable-diffusion==0.1.0) (3.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio->japanese-stable-diffusion==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from httpx->gradio->japanese-stable-diffusion==0.1.0) (0.15.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from httpx->gradio->japanese-stable-diffusion==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from importlib-metadata->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (3.8.0)\n",
      "Requirement already satisfied: torch in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from invisible-watermark->japanese-stable-diffusion==0.1.0) (1.12.1)\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.12.0-cp39-cp39-win_amd64.whl (11.5 MB)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from invisible-watermark->japanese-stable-diffusion==0.1.0) (4.6.0.66)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.12.1-cp39-cp39-win_amd64.whl (5.8 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from Jinja2->gradio->japanese-stable-diffusion==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio->japanese-stable-diffusion==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio->japanese-stable-diffusion==0.1.0) (1.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio->japanese-stable-diffusion==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio->japanese-stable-diffusion==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from matplotlib->gradio->japanese-stable-diffusion==0.1.0) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from matplotlib->gradio->japanese-stable-diffusion==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from matplotlib->gradio->japanese-stable-diffusion==0.1.0) (4.33.3)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from onnx->invisible-watermark->japanese-stable-diffusion==0.1.0) (3.19.4)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from onnxruntime->invisible-watermark->japanese-stable-diffusion==0.1.0) (1.12)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from pandas->gradio->japanese-stable-diffusion==0.1.0) (2022.1)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from paramiko->gradio->japanese-stable-diffusion==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from paramiko->gradio->japanese-stable-diffusion==0.1.0) (4.0.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from paramiko->gradio->japanese-stable-diffusion==0.1.0) (37.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from cryptography>=2.5->paramiko->gradio->japanese-stable-diffusion==0.1.0) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio->japanese-stable-diffusion==0.1.0) (2.21)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from tqdm->huggingface-hub>=0.8.1->diffusers@ git+https://github.com/huggingface/diffusers#egg=diffusers->japanese-stable-diffusion==0.1.0) (0.4.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from transformers->japanese-stable-diffusion==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages (from uvicorn->gradio->japanese-stable-diffusion==0.1.0) (8.1.3)\n",
      "Building wheels for collected packages: japanese-stable-diffusion, diffusers\n",
      "  Building wheel for japanese-stable-diffusion (setup.py): started\n",
      "  Building wheel for japanese-stable-diffusion (setup.py): finished with status 'done'\n",
      "  Created wheel for japanese-stable-diffusion: filename=japanese_stable_diffusion-0.1.0-py3-none-any.whl size=13933 sha256=7f5cc8b2a50759a53478925509ab7dc4a7396353e352fe711a661d8508fedf31\n",
      "  Stored in directory: C:\\Users\\tharh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-9uwfp_ke\\wheels\\63\\45\\39\\316a20d29354cd4302e61cb63eb5f7e1d20151fc070d845bcd\n",
      "  Building wheel for diffusers (PEP 517): started\n",
      "  Building wheel for diffusers (PEP 517): finished with status 'done'\n",
      "  Created wheel for diffusers: filename=diffusers-0.4.0.dev0-py3-none-any.whl size=159993 sha256=862b740093b338d78920cc8f48a203130288d8ea91cdfdc09ff527ea3549c766\n",
      "  Stored in directory: C:\\Users\\tharh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-9uwfp_ke\\wheels\\20\\4f\\c0\\c5897927e4b7b29eddf59cd32bfc5bf650803309be40f3068c\n",
      "Successfully built japanese-stable-diffusion diffusers\n",
      "Installing collected packages: pyreadline3, mpmath, humanfriendly, sympy, coloredlogs, PyWavelets, onnxruntime, onnx, invisible-watermark, diffusers, japanese-stable-diffusion\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.3.0\n",
      "    Uninstalling diffusers-0.3.0:\n",
      "      Successfully uninstalled diffusers-0.3.0\n",
      "Successfully installed PyWavelets-1.3.0 coloredlogs-15.0.1 diffusers-0.4.0.dev0 humanfriendly-10.0 invisible-watermark-0.1.5 japanese-stable-diffusion-0.1.0 mpmath-1.2.1 onnx-1.12.0 onnxruntime-1.12.1 pyreadline3-3.4.1 sympy-1.11.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/rinnakk/japanese-stable-diffusion 'C:\\Users\\tharh\\AppData\\Local\\Temp\\pip-req-build-galsb3pt'\n",
      "  Running command git clone -q https://github.com/huggingface/diffusers 'C:\\Users\\tharh\\AppData\\Local\\Temp\\pip-install-fx3qosx2\\diffusers_f75f5e710bde4b6487bfe7b1e6095203'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rinnakk/japanese-stable-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import LMSDiscreteScheduler\n",
    "from japanese_stable_diffusion import JapaneseStableDiffusionPipeline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_tokens = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrain model\n",
    "model_id = \"rinna/japanese-stable-diffusion\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Use the K-LMS scheduler here instead\n",
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "pipe = JapaneseStableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, use_auth_token=access_tokens)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"ブリーチなしのヘアカラーガイド。2022年秋冬のおすすめはこの7大カラー\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file outputs already exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86abc23e495458ea12472219ef49cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 8.00 GiB total capacity; 5.82 GiB already allocated; 0 bytes free; 6.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\gans\\git_upload\\keywords_to_img_research\\test_no.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39m# モデルにpromptを入力し画像生成\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39mwith\u001b[39;00m autocast(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     image \u001b[39m=\u001b[39m pipe(prompt, guidance_scale\u001b[39m=\u001b[39;49m\u001b[39m7.5\u001b[39;49m)[\u001b[39m\"\u001b[39m\u001b[39msample\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39m# 保存\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/gans/git_upload/keywords_to_img_research/test_no.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   image\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutputs/test_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m04\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:249\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[1;34m(self, prompt, height, width, num_inference_steps, guidance_scale, eta, generator, latents, output_type, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     latent_model_input \u001b[39m=\u001b[39m latent_model_input \u001b[39m/\u001b[39m ((sigma\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[0;32m    248\u001b[0m \u001b[39m# predict the noise residual\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m noise_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munet(latent_model_input, t, encoder_hidden_states\u001b[39m=\u001b[39;49mtext_embeddings)\u001b[39m.\u001b[39msample\n\u001b[0;32m    251\u001b[0m \u001b[39m# perform guidance\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39mif\u001b[39;00m do_classifier_free_guidance:\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\unet_2d_condition.py:234\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[1;34m(self, sample, timestep, encoder_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mfor\u001b[39;00m downsample_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_blocks:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(downsample_block, \u001b[39m\"\u001b[39m\u001b[39mattentions\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m downsample_block\u001b[39m.\u001b[39mattentions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m downsample_block(\n\u001b[0;32m    235\u001b[0m             hidden_states\u001b[39m=\u001b[39;49msample, temb\u001b[39m=\u001b[39;49memb, encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    237\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m downsample_block(hidden_states\u001b[39m=\u001b[39msample, temb\u001b[39m=\u001b[39memb)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\unet_blocks.py:537\u001b[0m, in \u001b[0;36mCrossAttnDownBlock2D.forward\u001b[1;34m(self, hidden_states, temb, encoder_hidden_states)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mfor\u001b[39;00m resnet, attn \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresnets, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattentions):\n\u001b[0;32m    536\u001b[0m     hidden_states \u001b[39m=\u001b[39m resnet(hidden_states, temb)\n\u001b[1;32m--> 537\u001b[0m     hidden_states \u001b[39m=\u001b[39m attn(hidden_states, context\u001b[39m=\u001b[39;49mencoder_hidden_states)\n\u001b[0;32m    538\u001b[0m     output_states \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (hidden_states,)\n\u001b[0;32m    540\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsamplers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\attention.py:148\u001b[0m, in \u001b[0;36mSpatialTransformer.forward\u001b[1;34m(self, hidden_states, context)\u001b[0m\n\u001b[0;32m    146\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(batch, height \u001b[39m*\u001b[39m weight, channel)\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks:\n\u001b[1;32m--> 148\u001b[0m     hidden_states \u001b[39m=\u001b[39m block(hidden_states, context\u001b[39m=\u001b[39;49mcontext)\n\u001b[0;32m    149\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mreshape(batch, height, weight, channel)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    150\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_out(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\attention.py:197\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[1;34m(self, hidden_states, context)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    196\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mcontiguous() \u001b[39mif\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m hidden_states\n\u001b[1;32m--> 197\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(hidden_states)) \u001b[39m+\u001b[39m hidden_states\n\u001b[0;32m    198\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(hidden_states), context\u001b[39m=\u001b[39mcontext) \u001b[39m+\u001b[39m hidden_states\n\u001b[0;32m    199\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(hidden_states)) \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\attention.py:265\u001b[0m, in \u001b[0;36mCrossAttention.forward\u001b[1;34m(self, hidden_states, context, mask)\u001b[0m\n\u001b[0;32m    260\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreshape_heads_to_batch_dim(value)\n\u001b[0;32m    262\u001b[0m \u001b[39m# TODO(PVP) - mask is currently never used. Remember to re-implement when used\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \n\u001b[0;32m    264\u001b[0m \u001b[39m# attention, what we cannot get enough of\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attention(query, key, value, sequence_length, dim)\n\u001b[0;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_out(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\diffusers\\models\\attention.py:279\u001b[0m, in \u001b[0;36mCrossAttention._attention\u001b[1;34m(self, query, key, value, sequence_length, dim)\u001b[0m\n\u001b[0;32m    277\u001b[0m end_idx \u001b[39m=\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m slice_size\n\u001b[0;32m    278\u001b[0m attn_slice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(query[start_idx:end_idx], key[start_idx:end_idx]\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\n\u001b[1;32m--> 279\u001b[0m attn_slice \u001b[39m=\u001b[39m attn_slice\u001b[39m.\u001b[39;49msoftmax(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    280\u001b[0m attn_slice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(attn_slice, value[start_idx:end_idx])\n\u001b[0;32m    282\u001b[0m hidden_states[start_idx:end_idx] \u001b[39m=\u001b[39m attn_slice\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 8.00 GiB total capacity; 5.82 GiB already allocated; 0 bytes free; 6.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "!mkdir outputs\n",
    "\n",
    "num = 5\n",
    "\n",
    "for i in range(num):\n",
    "  # モデルにpromptを入力し画像生成\n",
    "  with autocast(\"cuda\"):\n",
    "    image = pipe(prompt, guidance_scale=7.5)[\"sample\"][0] \n",
    "  # 保存\n",
    "  image.save(f\"outputs/test_{i:04}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tharhtet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46ff7e5b8b7911cfa9955e23e477c53e63d207f4b9ab3253a6a5ac7336ecbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
